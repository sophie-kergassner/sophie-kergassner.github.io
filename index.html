<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="color-bar" style="height:7vh"></div>
    <div class="container">
        
        <div class="section">

            <div class="headline">
                <div class="headline-name">
                    <h1>
                        Sophie Kergaßner
                    </h1>
                    <p class="headline-text-wide">
                        I am a PhD student under the supervision of <a class="text-link" href="https://pdf.inf.usi.ch">Prof. Piotr Didyk</a> at Università della Svizzera italiana in Lugano, Switzerland. 
                        My research interest lies in the quantification of human vision, and the manipulation of images for improved perceptual quality and efficient rendering, especially for AR/VR displays.
                    </p>
                </div>
                <img class="headline-image" src="img/Sophie_small.jpg" alt="Sophie Kergaßner">
            </div>

            <p class="headline-text-narrow">
                I am a second year PhD student under the supervision of <a class="text-link" href="https://pdf.inf.usi.ch">Prof. Piotr Didyk</a> at Università della Svizzera italiana in Lugano, Switzerland. 
                My research interest lies in the quantification of human vision, and the manipulation of images for improved perceptual quality and efficient rendering, especially for AR/VR displays.
            </p>

            <div class="button-container">
                <a class="button-link" href="mailto:sophie.kergassner@usi.ch">
                    <svg width="18" height="12" viewBox="9 0 18 24" fill="none" stroke="currentColor" stroke-width="3"><path d="M3 21L21 3M15 3h6v6" /></svg>
                    E-Mail
                </a>
                <a class="button-link" href="https://www.linkedin.com/in/sophie-kergassner/"> 
                    <svg width="18" height="12" viewBox="9 0 18 24" fill="none" stroke="currentColor" stroke-width="3"><path d="M3 21L21 3M15 3h6v6" /></svg>
                    LinkedIn
                </a>
                <a class="button-link" href="https://sophie-kergassner.github.io/cv.html">
                    <svg width="18" height="12" viewBox="9 0 18 24" fill="none" stroke="currentColor" stroke-width="3"><path d="M3 21L21 3M15 3h6v6" /></svg>
                    CV
                </a>
                <a class="button-link" href="https://orcid.org/0009-0000-4883-4694">    
                    <svg width="18" height="12" viewBox="9 0 18 24"" fill="none" stroke="currentColor" stroke-width="3"><path d="M3 21L21 3M15 3h6v6" /></svg>
                    ORCiD
                </a>
            </div>
        </div>

        <div class="section">
            <h2>Publications</h2>
            <!--<p>Please hold on while I finish this section... &#x1f6a7;</p>-->
            
            <div class="publication">
                <a style="display: contents" href="https://sophie-kergassner.github.io/depth-in-periphery.html">
                    <img class="publication-teaser" src="img/DisparityInPeriphery_Teaser.jpg">
                </a>

                <div class="publication-description">
                    <h3 class="publication-title">
                        <a href="https://sophie-kergassner.github.io/depth-in-periphery.html">
                            Towards Understanding Depth Perception in Foveated Rendering
                        </a>
                    </h3>

                    <p class="publication-authors">
                        <span class="author-highlight">Sophie Kergaßner</span>, Taimoor Tariq, Piotr Didyk
                    </p>

                    <p class="publication-venue" style="margin-top: 10px;">
                        <em>ACM SIGGRAPH 2025</em>
                    </p>

                    <p class="publication-summary">
                        We demonstrate that stereoacuity is remarkably resilient to foveated rendering and remains unaffected with up to 2× stronger foveation than commonly used. To this end, we design a psychovisual experiment and derive a simple perceptual model that determines the amount of foveation that does not affect stereoacuity.
                    </p>
                </div>
            </div>

            <div class="publication">
                <a style="display: contents" href="https://sophie-kergassner.github.io/hivefive360.html">
                    <img class="publication-teaser" src="img/HiveFive360_Teaser.png">
                </a>

                <div class="publication-description">
                    <h3 class="publication-title">
                        <a href="https://sophie-kergassner.github.io/hivefive360.html">
                            HiveFive360: Extending the VR Gaze Guidance Technique HiveFive to Highlight Out-Of-FOV Targets
                        </a>
                    </h3>

                    <p class="publication-authors">
                        <span class="author-highlight">Sophie Kergaßner</span>, Nina Doerr, Markus Wieland, Martin Fuchs, Michael Sedlmair
                    </p>

                    <p class="publication-venue">
                        <em>ACM Mensch und Computer 2024</em>
                    </p>

                    <p class="publication-award">
                        Honorable Mention Paper Award &#127941;
                    </p>

                    <p class="publication-summary">
                        We extend the gaze guidance technique <span style="font-style: italic;">HiveFive</span> to guide users to out-of-FOV targets. Our technique is qualitatively and quantitatively evaluated in two user studies. Our results show that HiveFive360 is effective in guiding users to a target object, and diegetic, meaning that the scenic immersion of the scene is preserved.
                    </p>
                </div>
            </div>

            <div class="publication">
                <a style="display: contents" href="https://doi.org/10.2352/EI.2023.35.2.SDA-383">
                    <img class="publication-teaser" src="img/SimulatedLightfield_Teaser.jpg">
                </a>

                <div class="publication-description">
                    <h3 class="publication-title">
                        <a href="https://doi.org/10.2352/EI.2023.35.2.SDA-383">
                            Evaluating the Angular Resolution of a Simulated Light Field Display in Regards to Three-Dimensionality, Motion Parallax and Viewing Experience
                        </a>
                    </h3>

                    <p class="publication-authors">
                        <span class="author-highlight">Sophie Kergaßner</span>, Jan Fröhlich
                    </p>

                    <p class="publication-venue">
                        <em>Electronic Imaging (Stereoscopic Displays & Applications) 2023</em>
                    </p>

                    <p class="publication-summary">
                        We show that the viewing experience of a multiview screen increases logarithmically with the presented number of views.
                        This rise stagnates at around 0.25° per view. Below 0.5° per view, participants prefer a common 2D display.
                    </p>

                    <!-- <a class="publication-link" href="https://doi.org/10.2352/EI.2023.35.2.SDA-383">Paper</a> -->
                </div>
            </div>
        </div>
    </div>
    <div class="color-bar" style="height:25vh"></div>
</body>
</html>